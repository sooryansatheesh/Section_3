{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "kwjNQbJl1ZD5"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# Generate random dates in string format\n",
        "def generate_random_date_string(start_date, end_date):\n",
        "    delta = end_date - start_date\n",
        "    random_days = random.randint(0, delta.days)\n",
        "    random_date = start_date + timedelta(days=random_days)\n",
        "    return random_date.strftime('%Y-%m-%d')\n",
        "\n",
        "start_date = datetime(2020, 1, 1)\n",
        "end_date = datetime(2023, 12, 31)\n",
        "\n",
        "\n",
        "# Creating dummy data with a million records\n",
        "num_records = 1000000\n",
        "sale_ids = range(1, num_records + 1)\n",
        "product_ids = [random.randint(1, 50) for _ in range(num_records)]\n",
        "quantities_sold = [random.randint(1, 20) for _ in range(num_records)]\n",
        "sale_dates = [generate_random_date_string(start_date, end_date) for _ in range(num_records)]\n",
        "sale_amounts = [round(random.uniform(5.0, 1000.0), 2) for _ in range(num_records)]\n",
        "\n",
        "# Create a DataFrame with the dummy data\n",
        "sales_data = pd.DataFrame({\n",
        "    'sale_id': sale_ids,\n",
        "    'product_id': product_ids,\n",
        "    'quantity_sold': quantities_sold,\n",
        "    'sale_date': sale_dates,\n",
        "    'sale_amount': sale_amounts\n",
        "})\n",
        "\n",
        "# Saving to CSV\n",
        "file_name = 'sales_data.csv' #sales_data.csv has 1 million records\n",
        "sales_data.to_csv(file_name, index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the datatype of each column\n",
        "print(\"Datatype of the different columns in the Original Dataframe\\n\",sales_data.dtypes)\n",
        "print(\"\\nMemory usage of the different columns in the Original Dataframe\\n\",sales_data.memory_usage(deep=True))  # memory usage in bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwaV82pYkNH6",
        "outputId": "56c0b0b6-bde8-42da-fed5-3ca46260a8f4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of the different columns in the Original Dataframe\n",
            " sale_id            int64\n",
            "product_id         int64\n",
            "quantity_sold      int64\n",
            "sale_date         object\n",
            "sale_amount      float64\n",
            "dtype: object\n",
            "\n",
            "Memory usage of the different columns in the Original Dataframe\n",
            " Index                 128\n",
            "sale_id           8000000\n",
            "product_id        8000000\n",
            "quantity_sold     8000000\n",
            "sale_date        67000000\n",
            "sale_amount       8000000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the CSV file into a DataFrame\n",
        "sales_data_df = pd.read_csv(file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHZcOuS22k-1",
        "outputId": "a64bd690-7032-4221-88b8-6acf8f98300b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        sale_id  product_id  quantity_sold   sale_date  sale_amount\n",
            "0             1          32             19  2023-09-16       540.07\n",
            "1             2          36              1  2022-09-25       626.29\n",
            "2             3          28              4  2022-10-29       745.31\n",
            "3             4          46             10  2021-04-21       867.50\n",
            "4             5          18             15  2020-01-06       486.18\n",
            "...         ...         ...            ...         ...          ...\n",
            "999995   999996           6             14  2021-03-25        87.02\n",
            "999996   999997          46             10  2021-03-31       633.23\n",
            "999997   999998          29             10  2022-02-09       775.78\n",
            "999998   999999          32              1  2020-12-14       252.05\n",
            "999999  1000000           8             11  2022-03-21       499.64\n",
            "\n",
            "[1000000 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Improving efficiency by using better data types\n",
        "\n",
        "Default Pandas data types are not very efficient. So to reduce the data usage we convert to more efficient data types."
      ],
      "metadata": {
        "id": "eOHRw89qF9H8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the datatype of each column\n",
        "print(\"Datatype of the different columns in the Original Dataframe\\n\",sales_data_df.dtypes)\n",
        "print(\"\\nMemory usage of the different columns in the Original Dataframe\\n\",sales_data_df.memory_usage(deep=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px_yfAbqF38u",
        "outputId": "8e96bd6f-4670-4b7f-f0b8-45a1274bbeed"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of the different columns in the Original Dataframe\n",
            " sale_id            int64\n",
            "product_id         int64\n",
            "quantity_sold      int64\n",
            "sale_date         object\n",
            "sale_amount      float64\n",
            "dtype: object\n",
            "\n",
            "Memory usage of the different columns in the Original Dataframe\n",
            " Index                 128\n",
            "sale_id           8000000\n",
            "product_id        8000000\n",
            "quantity_sold     8000000\n",
            "sale_date        67000000\n",
            "sale_amount       8000000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Copying the dataframe to a new one for new efficient data types\n",
        "sales_data_df2=sales_data_df.copy()\n"
      ],
      "metadata": {
        "id": "JZwhH-TQF8t7"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking range for integer columns to decide optimum data type\n",
        "print(\"sale_id range:\", sales_data_df2['sale_id'].min(), \"-\", sales_data_df2['sale_id'].max())\n",
        "print(\"product_id range:\", sales_data_df2['product_id'].min(), \"-\", sales_data_df2['product_id'].max())\n",
        "print(\"quantity_sold range:\", sales_data_df2['quantity_sold'].min(), \"-\", sales_data_df2['quantity_sold'].max())\n",
        "\n",
        "# Checking precision for float columns\n",
        "print(\"sale_amount precision check:\")\n",
        "print(sales_data_df2['sale_amount'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC3vrWPuIWTM",
        "outputId": "cceca83e-7726-4c48-9bed-2df16581b797"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sale_id range: 1 - 1000000\n",
            "product_id range: 1 - 50\n",
            "quantity_sold range: 1 - 20\n",
            "sale_amount precision check:\n",
            "count    1000000.000000\n",
            "mean         502.376477\n",
            "std          287.448846\n",
            "min            5.000000\n",
            "25%          253.050000\n",
            "50%          502.110000\n",
            "75%          751.550000\n",
            "max         1000.000000\n",
            "Name: sale_amount, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the identified data ranges of the various columns, we can make the following datatype conversions to optimize memory usage:\n",
        "\n",
        "\n",
        "\n",
        "1.   sale_id: Since the range is from 1 to 1,000,000, we can use uint32 (unsigned 32-bit integer). This type can hold values from 0 to 4,294,967,295, which is more than enough for our range (1 to 1,000,000).\n",
        "2.   product_id: Since the range is from 1 to 50, we can use uint8 (unsigned 8-bit integer). This type can hold values from 0 to 255, which is sufficient for our range (1 to 50).\n",
        "3.   quantity_sold: Since the range is from 1 to 20, we can use uint8 (unsigned 8-bit integer). This type can hold values from 0 to 255, which is sufficient for our range (1 to 20).\n",
        "4.   sale_date: Convert to datetime64[ns].This type efficiently handles datetime data.\n",
        "\n",
        "\n",
        "sale_amount: Given the precision and range, we can use float32. But when converting from float64 to float32, minor variations occur due to the difference in precision between these two data types. float32 has fewer bits for precision, which can lead to small inaccuracies in the representation of the data. This can increase bigger errors when aggregating the sale_amount value so it was kept at float64.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zVpMUwS5JNoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert integer columns to more efficient types\n",
        "sales_data_df2['sale_id'] = pd.to_numeric(sales_data_df2['sale_id'], downcast='unsigned')\n",
        "sales_data_df2['product_id'] = sales_data_df2['product_id'].astype('uint8')\n",
        "sales_data_df2['quantity_sold'] = sales_data_df2['quantity_sold'].astype('uint8')\n",
        "\n",
        "# Convert sale_date to datetime from string\n",
        "sales_data_df2['sale_date'] = pd.to_datetime(sales_data_df2['sale_date'])\n",
        "\n",
        "# Print the optimized dtypes and memory usage\n",
        "print(\"\\nOptimized dtypes:\")\n",
        "print(sales_data_df2.dtypes)\n",
        "print(\"\\nOptimized memory usage:\")\n",
        "print(sales_data_df2.memory_usage(deep=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So8ePDvfJpWs",
        "outputId": "afbbb6f8-9846-48ce-8c7b-0a9fa3c6d887"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized dtypes:\n",
            "sale_id                  uint32\n",
            "product_id                uint8\n",
            "quantity_sold             uint8\n",
            "sale_date        datetime64[ns]\n",
            "sale_amount             float64\n",
            "dtype: object\n",
            "\n",
            "Optimized memory usage:\n",
            "Index                128\n",
            "sale_id          4000000\n",
            "product_id       1000000\n",
            "quantity_sold    1000000\n",
            "sale_date        8000000\n",
            "sale_amount      8000000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduction = sales_data_df2.memory_usage(deep=True).sum() / sales_data_df.memory_usage(deep=True).sum()\n",
        "\n",
        "print(f\"Reduction in memory usage(%)-{(reduction*100):0.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35gbeQPFNXSy",
        "outputId": "e766b7c4-ecd9-4578-dcf1-e268464f9934"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduction in memory usage(%)-22.22 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the 1 million row dataset to 50 parquet files for each product id\n",
        "\n",
        "Since we have to do aggregation based on product id, we split the original dataset into separate parquet files. Then each of these files are processed separately using parallel processing."
      ],
      "metadata": {
        "id": "NtxdzJKXkz0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure the 'product_data' directory exists\n",
        "output_dir = 'product_data'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Iterate over each product_id and save the corresponding dataframe to a Parquet file\n",
        "for product_id in range(1, 51):  # Assuming product IDs are from 1 to 50\n",
        "    product_df = sales_data_df2[sales_data_df2['product_id'] == product_id]\n",
        "    if not product_df.empty:\n",
        "        file_name = f'{output_dir}/product_{product_id}.parquet'\n",
        "        product_df.to_parquet(file_name, index=False)\n",
        "        print(f'Saved {file_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNsc8yK8OX05",
        "outputId": "736ef8f4-6088-49c5-e740-dbedc8b87186"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved product_data/product_1.parquet\n",
            "Saved product_data/product_2.parquet\n",
            "Saved product_data/product_3.parquet\n",
            "Saved product_data/product_4.parquet\n",
            "Saved product_data/product_5.parquet\n",
            "Saved product_data/product_6.parquet\n",
            "Saved product_data/product_7.parquet\n",
            "Saved product_data/product_8.parquet\n",
            "Saved product_data/product_9.parquet\n",
            "Saved product_data/product_10.parquet\n",
            "Saved product_data/product_11.parquet\n",
            "Saved product_data/product_12.parquet\n",
            "Saved product_data/product_13.parquet\n",
            "Saved product_data/product_14.parquet\n",
            "Saved product_data/product_15.parquet\n",
            "Saved product_data/product_16.parquet\n",
            "Saved product_data/product_17.parquet\n",
            "Saved product_data/product_18.parquet\n",
            "Saved product_data/product_19.parquet\n",
            "Saved product_data/product_20.parquet\n",
            "Saved product_data/product_21.parquet\n",
            "Saved product_data/product_22.parquet\n",
            "Saved product_data/product_23.parquet\n",
            "Saved product_data/product_24.parquet\n",
            "Saved product_data/product_25.parquet\n",
            "Saved product_data/product_26.parquet\n",
            "Saved product_data/product_27.parquet\n",
            "Saved product_data/product_28.parquet\n",
            "Saved product_data/product_29.parquet\n",
            "Saved product_data/product_30.parquet\n",
            "Saved product_data/product_31.parquet\n",
            "Saved product_data/product_32.parquet\n",
            "Saved product_data/product_33.parquet\n",
            "Saved product_data/product_34.parquet\n",
            "Saved product_data/product_35.parquet\n",
            "Saved product_data/product_36.parquet\n",
            "Saved product_data/product_37.parquet\n",
            "Saved product_data/product_38.parquet\n",
            "Saved product_data/product_39.parquet\n",
            "Saved product_data/product_40.parquet\n",
            "Saved product_data/product_41.parquet\n",
            "Saved product_data/product_42.parquet\n",
            "Saved product_data/product_43.parquet\n",
            "Saved product_data/product_44.parquet\n",
            "Saved product_data/product_45.parquet\n",
            "Saved product_data/product_46.parquet\n",
            "Saved product_data/product_47.parquet\n",
            "Saved product_data/product_48.parquet\n",
            "Saved product_data/product_49.parquet\n",
            "Saved product_data/product_50.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the 'processed_data' directory exists\n",
        "output_dir = 'processed_data'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Function to process each Parquet file\n",
        "def process_parquet_file(product_id):\n",
        "    input_file = f'product_data/product_{product_id}.parquet'\n",
        "    output_file = f'{output_dir}/product_{product_id}_processed.parquet'\n",
        "\n",
        "    # Read the Parquet file\n",
        "    df = pd.read_parquet(input_file)\n",
        "\n",
        "    # Add year_month column\n",
        "    df['year_month'] = df['sale_date'].dt.to_period('M')\n",
        "\n",
        "    # Calculate total sales amount per product per month\n",
        "    result_df = df.groupby(['product_id', 'year_month']).agg(total_sales_amount=('sale_amount', 'sum')).reset_index()\n",
        "\n",
        "    # Write the result to a new Parquet file\n",
        "    result_df.to_parquet(output_file, index=False)\n",
        "    print(f'Processed and saved {output_file}')\n",
        "    return result_df,df\n",
        "\n",
        "# List of product IDs (1 to 50)\n",
        "product_ids = list(range(1, 51))\n",
        "\n",
        "# Process files in parallel using ThreadPoolExecutor\n",
        "#Each product file is processed separately in a parallel process using ThreadPoolExecutor\n",
        "results = []\n",
        "df_chunks = []\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "     for res, df_chunk in executor.map(process_parquet_file, product_ids):\n",
        "        results.append(res)\n",
        "        df_chunks.append(df_chunk)\n",
        "\n",
        "# Combining all results into a single DataFrames\n",
        "aggregate_result = pd.concat(results)\n",
        "final_df = pd.concat(df_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcrFerdlRsHf",
        "outputId": "5ce1292a-3611-4a6d-d98a-21caed134541"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved processed_data/product_2_processed.parquet\n",
            "Processed and saved processed_data/product_1_processed.parquet\n",
            "Processed and saved processed_data/product_5_processed.parquet\n",
            "Processed and saved processed_data/product_3_processed.parquet\n",
            "Processed and saved processed_data/product_6_processed.parquet\n",
            "Processed and saved processed_data/product_4_processed.parquet\n",
            "Processed and saved processed_data/product_7_processed.parquet\n",
            "Processed and saved processed_data/product_9_processed.parquet\n",
            "Processed and saved processed_data/product_8_processed.parquet\n",
            "Processed and saved processed_data/product_10_processed.parquet\n",
            "Processed and saved processed_data/product_11_processed.parquet\n",
            "Processed and saved processed_data/product_14_processed.parquet\n",
            "Processed and saved processed_data/product_12_processed.parquet\n",
            "Processed and saved processed_data/product_15_processed.parquet\n",
            "Processed and saved processed_data/product_13_processed.parquet\n",
            "Processed and saved processed_data/product_16_processed.parquet\n",
            "Processed and saved processed_data/product_18_processed.parquet\n",
            "Processed and saved processed_data/product_17_processed.parquet\n",
            "Processed and saved processed_data/product_19_processed.parquetProcessed and saved processed_data/product_20_processed.parquet\n",
            "\n",
            "Processed and saved processed_data/product_22_processed.parquet\n",
            "Processed and saved processed_data/product_21_processed.parquet\n",
            "Processed and saved processed_data/product_23_processed.parquet\n",
            "Processed and saved processed_data/product_24_processed.parquet\n",
            "Processed and saved processed_data/product_25_processed.parquet\n",
            "Processed and saved processed_data/product_26_processed.parquet\n",
            "Processed and saved processed_data/product_30_processed.parquetProcessed and saved processed_data/product_28_processed.parquet\n",
            "Processed and saved processed_data/product_27_processed.parquet\n",
            "\n",
            "Processed and saved processed_data/product_29_processed.parquet\n",
            "Processed and saved processed_data/product_33_processed.parquet\n",
            "Processed and saved processed_data/product_31_processed.parquet\n",
            "Processed and saved processed_data/product_34_processed.parquetProcessed and saved processed_data/product_32_processed.parquet\n",
            "Processed and saved processed_data/product_35_processed.parquet\n",
            "\n",
            "Processed and saved processed_data/product_36_processed.parquet\n",
            "Processed and saved processed_data/product_39_processed.parquet\n",
            "Processed and saved processed_data/product_38_processed.parquet\n",
            "Processed and saved processed_data/product_41_processed.parquet\n",
            "Processed and saved processed_data/product_40_processed.parquet\n",
            "Processed and saved processed_data/product_37_processed.parquet\n",
            "Processed and saved processed_data/product_44_processed.parquet\n",
            "Processed and saved processed_data/product_42_processed.parquet\n",
            "Processed and saved processed_data/product_43_processed.parquet\n",
            "Processed and saved processed_data/product_45_processed.parquetProcessed and saved processed_data/product_46_processed.parquet\n",
            "\n",
            "Processed and saved processed_data/product_47_processed.parquet\n",
            "Processed and saved processed_data/product_49_processed.parquet\n",
            "Processed and saved processed_data/product_48_processed.parquetProcessed and saved processed_data/product_50_processed.parquet\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the final result\n",
        "print(aggregate_result.head(10))\n",
        "# Print the datatype of each column\n",
        "print(\"Datatype of the different columns in the Aggregate Result Dataframe\\n\",aggregate_result.dtypes)\n",
        "print(f'Shape of Aggregate Result Dataframe-{aggregate_result.shape}')\n",
        "\n",
        "print(f'\\n Since there are 50 products sold in 4 years with 12 months each,\\n we need to have maximum of 50*4*12=2400 rows in the aggregate result table')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aszfMhm75JqA",
        "outputId": "24380e04-9f08-4c49-a9e1-8733bfc6e3f0"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_id year_month  total_sales_amount\n",
            "0           1    2020-01           200965.95\n",
            "1           1    2020-02           195312.01\n",
            "2           1    2020-03           205651.19\n",
            "3           1    2020-04           197658.97\n",
            "4           1    2020-05           207338.64\n",
            "5           1    2020-06           217745.13\n",
            "6           1    2020-07           213160.15\n",
            "7           1    2020-08           210664.96\n",
            "8           1    2020-09           241199.34\n",
            "9           1    2020-10           198068.03\n",
            "Datatype of the different columns in the Aggregate Result Dataframe\n",
            " product_id                uint8\n",
            "year_month            period[M]\n",
            "total_sales_amount      float64\n",
            "dtype: object\n",
            "Shape of Aggregate Result Dataframe-(2400, 3)\n",
            "\n",
            " Since there are 50 products sold in 4 years with 12 months each,\n",
            " we need to have maximum of 50*4*12=2400 rows in the aggregate result table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the final transformed dataframe\n",
        "print(final_df.head(10))\n",
        "\n",
        "# Print the datatype of each column\n",
        "print(\"Datatype of the different columns in the Transformed Dataframe\\n\",final_df.dtypes)\n",
        "\n",
        "print(f'Shape of Transformed Dataframe-{final_df.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe5wB9zVW5Tj",
        "outputId": "6552c4af-6440-4d0c-ff8a-b29f5d6bee83"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sale_id  product_id  quantity_sold  sale_date  sale_amount year_month\n",
            "0       51           1             19 2023-02-08       577.39    2023-02\n",
            "1      116           1              5 2022-08-19       335.59    2022-08\n",
            "2      154           1             14 2021-05-20        98.07    2021-05\n",
            "3      185           1             17 2023-08-09       917.19    2023-08\n",
            "4      198           1             19 2020-12-25        35.09    2020-12\n",
            "5      275           1             19 2021-08-12       914.90    2021-08\n",
            "6      309           1              1 2021-04-11       525.18    2021-04\n",
            "7      348           1             18 2023-01-08       213.05    2023-01\n",
            "8      362           1              6 2023-07-13        65.70    2023-07\n",
            "9      423           1              7 2023-06-19       882.21    2023-06\n",
            "Datatype of the different columns in the Transformed Dataframe\n",
            " sale_id                  uint32\n",
            "product_id                uint8\n",
            "quantity_sold             uint8\n",
            "sale_date        datetime64[ns]\n",
            "sale_amount             float64\n",
            "year_month            period[M]\n",
            "dtype: object\n",
            "Shape of Transformed Dataframe-(1000000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is8ZKwER4xuv",
        "outputId": "fbbddb6e-3746-4822-ee7d-6973ad171d6a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sale_id  product_id  quantity_sold  sale_date  sale_amount year_month\n",
            "0        5          18             15 2020-01-06       486.18    2020-01\n",
            "0        8          24             18 2021-04-13       956.60    2021-04\n",
            "0        3          28              4 2022-10-29       745.31    2022-10\n",
            "0        1          32             19 2023-09-16       540.07    2023-09\n",
            "0        2          36              1 2022-09-25       626.29    2022-09\n",
            "0        6          43              5 2022-07-16       926.20    2022-07\n",
            "0        9          45             20 2023-06-25       949.86    2023-06\n",
            "0        4          46             10 2021-04-21       867.50    2021-04\n",
            "0        7          50              6 2022-01-22       691.37    2022-01\n",
            "   sale_id  product_id  quantity_sold  sale_date  sale_amount\n",
            "0        1          32             19 2023-09-16       540.07\n",
            "1        2          36              1 2022-09-25       626.29\n",
            "2        3          28              4 2022-10-29       745.31\n",
            "3        4          46             10 2021-04-21       867.50\n",
            "4        5          18             15 2020-01-06       486.18\n",
            "5        6          43              5 2022-07-16       926.20\n",
            "6        7          50              6 2022-01-22       691.37\n",
            "7        8          24             18 2021-04-13       956.60\n",
            "8        9          45             20 2023-06-25       949.86\n",
            "   sale_id  product_id  quantity_sold   sale_date  sale_amount\n",
            "0        1          32             19  2023-09-16       540.07\n",
            "1        2          36              1  2022-09-25       626.29\n",
            "2        3          28              4  2022-10-29       745.31\n",
            "3        4          46             10  2021-04-21       867.50\n",
            "4        5          18             15  2020-01-06       486.18\n",
            "5        6          43              5  2022-07-16       926.20\n",
            "6        7          50              6  2022-01-22       691.37\n",
            "7        8          24             18  2021-04-13       956.60\n",
            "8        9          45             20  2023-06-25       949.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCdlDWdnENJu"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUiT0GN1iLgs"
      },
      "execution_count": 102,
      "outputs": []
    }
  ]
}